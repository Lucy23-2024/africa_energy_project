# ğŸŒ Energy Data Extraction and MongoDB Storage (2000â€“2024)

## ğŸ“˜ Overview
This project extracts **energy-related data for African countries (2000â€“2024)** from the **Africa Energy Portal (AEP)**, formats it according to a standard schema, and stores it in **MongoDB**.  

It was completed as part of the **Internship Week 1** task on *Energy Data Extraction and MongoDB Storage*.  

---

## ğŸ—‚ï¸ Project Structure
```
AFRICA_ENERGY_PROJECT/
â”‚
â”œâ”€â”€ venv/                         # Virtual environment folder
â”œâ”€â”€ .gitignore                    # Files and folders to ignore in GitHub
â”œâ”€â”€ .python-version               # Python version configuration
â”œâ”€â”€ africa_energy_data.ipynb      # Main Jupyter Notebook (data processing workflow)
â”œâ”€â”€ africa_energy_data.csv        # Final processed dataset (ready for MongoDB)
â”œâ”€â”€ electricity.json              # Raw JSON data (electricity indicators)
â”œâ”€â”€ energy.json                   # Raw JSON data (energy indicators)
â”œâ”€â”€ social_and_economic.json      # Raw JSON data (social and economic indicators)
â”œâ”€â”€ main.py                       # Optional script version of notebook logic
â”œâ”€â”€ pyproject.toml                # Python project dependencies/config
â””â”€â”€ README.md                     # Project documentation (this file)
```

ğŸ’¡ *Note:* The `.json` files are the manually downloaded datasets from the Africa Energy Portal.  
They are combined and cleaned within the Jupyter notebook.

---

## ğŸ§© Project Workflow

### 1. **Data Collection**
- Data was obtained manually from the **[Africa Energy Portal](https://africa-energy-portal.org/)**.
- Using browser developer tools, the **Network â†’ Response** tab revealed API responses in JSON format.
- The JSON data was **copied**, **saved in Notepad**, and stored as `.json` files.
- These files were then processed using Python.

---

### 2. **Data Processing Steps**

| Step | Description |
|------|--------------|
| **1. Import Libraries & Load Data** | Used `glob` to load all JSON files and combine them into one dataset. |
| **2. Rename Columns** | Standardized field names to match the internship schema. |
| **3. Clean Data** | Converted non-numeric fields like `"N/A"` to proper numbers. |
| **4. Pivot Table** | Transformed data so each year (2000â€“2024) became a column. |
| **5. Save Final CSV** | Exported the cleaned dataset as `africa_energy_data.csv` ready for MongoDB. |

---

### 3. **Expected Data Format**

| country | country_serial | metric | unit | sector | sub_sector | source_link | source | 2000 | 2001 | ... | 2024 |
|----------|----------------|--------|------|---------|-------------|-------------|--------|------|------|-----|------|
| Kenya | KE | Electricity generation | GWh | Energy | Electricity | /aep/country/kenya | AEP | 4500 | 4600 | ... | 9200 |

---

## ğŸ—„ï¸ MongoDB Storage

After exporting the cleaned dataset (`africa_energy_data.csv`), it was inserted into a **MongoDB** collection.  
Each record represents **one energy metric for one country** across the years 2000â€“2024.

The MongoDB collection mirrors the CSV structure â€” with text fields for identifiers and numeric fields for each year.

### Example Document
```json
{
  "country": "Kenya",
  "metric": "Electricity access",
  "unit": "%",
  "sector": "Energy",
  "source": "AEP",
  "2000": 36.5,
  "2001": 38.2,
  "...": "...",
  "2024": 75.1
}
```

---

## âœ… Validation & Checks

| Check | Description |
|-------|--------------|
| **Missing Years** | Verified coverage for all years (2000â€“2024). |
| **Consistency** | Standardized country names and units. |
| **Data Types** | Ensured numeric values are correctly formatted. |

---

## ğŸ§° Technologies Used
- **Python** â†’ `pandas`, `json`, `glob`
- **MongoDB** â†’ NoSQL database for data storage
- **Africa Energy Portal** â†’ Primary data source

---

## ğŸ‘©ğŸ½â€ğŸ’» Author
**Lucy Joan**  
Intern â€“ Lux Academy  
